<!DOCTYPE html>
<html class="gr__people_csail_mit_edu"><head>


<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<title>董师周</title>

<link rel="stylesheet" href="./imgs/bootstrap.min.css">
<style type="text/css"> 

body
{
	font-family: 'Source Sans Pro', sans-serif;
    background-color : #CDCDCD;
    font-size: 19px;
}
    .content
	{
    		width : 900px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 850px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 820px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #1367a7;
		height: 158px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    #mit_logo {
        position: absolute;
        left: 646px;
        top: 14px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
    }
</style>

<script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-23931362-2', 'mit.edu');
  ga('send', 'pageview');

</script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-23931362-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

    var myPix = new Array("image/profile_correct.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };

</script>
<style>#haloword-pron { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -94px -34px; }#haloword-pron:hover { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -111px -34px; }#haloword-open { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -94px -17px; }#haloword-open:hover { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -111px -17px; }#haloword-close { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -94px 0; }#haloword-close:hover { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -111px 0; }#haloword-add { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -94px -51px; }#haloword-add:hover { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -111px -51px; }#haloword-remove { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -94px -68px; }#haloword-remove:hover { background: url(chrome-extension://bhkcehpnnlgncpnefpanachijmhikocj/img/icon.svg) -111px -68px; }</style></head>


<body data-gr-c-s-loaded="true">
<div class="content">
	<div id="container">
	<table>
		<tbody>
		<tr>
			<td><img id="myPicture" src="./imgs/profile_correct.jpg" style="float:left; padding-right:10px" height="200px"></td>
			<td>
				<div id="DocInfo">
					<h1>董师周</h1>
					2020年7月毕业于中国科学院大学-深圳先进技术研究院 <br>
					硕士研究生 <br>
					Phone:18883841206 <br>
					Email: shizhoudong@126.com <!--<img src="./imgs/email.png" height="20px">--> <br>
					<a href="./dszCV.pdf">CV</a> • <a href="https://scholar.google.com.hk/citations?user=frMvE9sAAAAJ&hl=zh-CN">Google Scholar</a> • <a href="https://github.com/jack-Dong">Github</a>• <a href="https://blog.csdn.net/xiaoxiaodongshige">CSDN</a>
				</div><br>
			</td>
		</tr>
		</tbody>
	</table>

	<h2>个人经历</h2>
    <ul>
		<li>我是中国科学院大学-深圳先进技术研究院计算机专业的研究生，目前在云从科技工作，工作主要涉及大语言模型人类偏好对齐，大规模场景下的人脸人体时空聚类，超高客流统计相关工作。</li>
		<li>研究生期间研究方向是基于深度学习的显著性检测，熟悉语义分割，显著性检测，半监督学习相关领域，并跟随深圳先进技术研究院数字所多媒体中心（Siat-MMLab）的<a href="http://mmlab.siat.ac.cn/yuqiao/">乔宇老师</a>和 <a href="http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170727_181385.html">王亚立老师</a> 做视频分类相关工作。</li>
        <li>我本科毕业于重庆邮电大学计算机科学与技术专业，从大二开始在陈乔松老师实验室学习图像处理相关知识。 </li>
    </ul>
      
	
    <h2>最近消息</h2>
    <ul>
		<li>2024-06-11:我最近在寻找大语言模型优化或计算机视觉算法相关机会，目标地：重庆，成都，欢迎各位HR联系我！
		<li>2023-10-06:<a href="https://mp.weixin.qq.com/s/sSiWB38X12_mA0SEIn3eSA"> 我们项目组的模型在SuperCLUE4月测试中国内排名第六。 </a>
		<li>2023-10-06:我在知乎专栏中更新了文章： <a href="https://zhuanlan.zhihu.com/p/338274678"> LLM之我见 </a>
		<li>2021-03-28:我在知乎专栏中更新了文章： <a href="https://zhuanlan.zhihu.com/p/640882729"> 用二进制编码代替one-hot编码训练分类器 </a>
		<li>2020-09-07:已入职<a href="https://www.cloudwalk.cn/"> 云从科技（重庆）</a>，并在入职培训中笔试成绩第一名。
		<li>2020-06-12:我将会在8.31号入职<a href="https://www.cloudwalk.cn/"> 云从科技（重庆）。</a>
		<li>2020-06-11:我在知乎专栏中更新了文章： <a href="https://zhuanlan.zhihu.com/p/72743589"> 图像分割的难点在哪里？ </a>
        <li>2019-07-08:我正在找计算机视觉方向的全职研发工作，目标岗位为计算机视觉算法工程师，欢迎各位HR姐姐联系我！
    </ul>
	<h2>项目经历</h2>
	<table class="pub_table">
	<tbody>
        <tr>
			<!-- <td class="pub_td1"><img src="./imgs/license_plate.png" class="papericon"></td>
            <td class="pub_td2"> -->
		    <b>1.大语言模型的人类偏好对齐</b><br>
			主要负责大语言模型的指令微调，偏好对齐相关算法的探索和训练。具体包括：<br>
			1.探索偏好对齐算法，包括DPO，ORPO，SimPO等高效实现和训练。<br>
			2.指令微调和偏好对齐的数据构造和筛选。<br>
			3.大语言模型的工具调用流程设计以及数据构造。<br>
			4.模型的推理测试和错误样例分析与总结。<br>
			<b>亮点  <li>参与训练的从容大语言模型在SuperCLUE在2023年12月测试中国内排名第一，2024年2月国内排名第九，4月排名第六。</li>
					<li>偏好对齐模型相对语指令微调模型在内部测试集上提升5个点以上。</li>
			</b><br>
			</td>
		</tr>
		<hr />
		<tr>
			<!-- <td class="pub_td1"><img src="./imgs/license_plate.png" class="papericon"></td>
            <td class="pub_td2"> -->
		    <b>2.大规模场景下的人脸人体时空聚类</b><br>
			主要负责市级人脸聚类中和封闭场景下人脸人体的轨迹时空模型设计与实现。具体包括：<br>
			1.市级别的基于相机GPS的时空模型设计与实现。<br>
			2.商场，4S店等封闭场景下的行人轨迹时空设计与实现。<br>
			<b>亮点  <li>成功落地于公司的多个实际项目。</li>
					<li>有效提升低质量人脸人体的聚类效果，减少90%以上的大乱档。</li>
			</b><br>
			</td>
		</tr>
		<hr />
		<tr>
			<!-- <td class="pub_td1"><img src="./imgs/license_plate.png" class="papericon"></td>
            <td class="pub_td2"> -->
		    <b>3.超高客流统计</b><br>
			主要负责基于行人轨迹的客流统计算法的设计与实现。具体包括：<br>
			1.独立设计与开发基于行人轨迹的客流算法SDK。<br>
			2.能够规避掉大多数情况下的徘徊人员的影响。<br>
			3.完成店铺，街道，楼梯等场景优化与测试，泛化性强。<br>
			<b>亮点  <li>成功落地于公司的多个实际项目，在多次PK中，超过友商。</li>
					<li>普通场景下准确率95%以上，超高客流（4000+人次/小时）下依然有92%的准确率。</li>
			</b><br>
			</td>
		</tr>
		 
	</tbody></table>

	<h2>论文研究</h2>
	<table class="pub_table">
	<tbody>
        <tr>
           <td class="pub_td1"><img src="./imgs/holisticbmvc2018.png" class="papericon"></td>
           <td class="pub_td2">
			<u>Shizhou Dong</u>,Shanhui Sun,Xin Wang, Ming Li,Heye Zhang,Guang Yang,Huafeng Liu,Shuo Li<br>
			<b>Holistic and deep feature pyramids for saliency detection.</b><br>
			BMVC 2018<br>
			<b>优点：性能位于行业领先水平，分割边缘准确，不需要预训练。</b><br>
			[<a href="https://www.researchgate.net/profile/Shuo_Li4/publication/327834120_Holistic_and_Deep_Feature_Pyramids_for_Saliency_Detection/links/5ba7f04f45851574f7e19958/Holistic-and-Deep-Feature-Pyramids-for-Saliency-Detection.pdf">PDF</a>]
			</td>
		 </tr>
		 
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/saliencygan.png" class="papericon"></td>
           <td class="pub_td2">
		   
			Chengjia Wang*, <u>Shizhou Dong*</u>, Heye Zhang<br> 
			<b>SaliencyGAN: Deep Learning Semi-supervised Salient Object Detection</b><br>
			IEEE Transactions on Industrial Informatics(SCI一区，IF:7.377)，被引用超100次<br>
			<b>优点：减少 70% 的需要标注的训练数据,用 3K 有标注图像训练性能就能超过弱监督算法，接近 10K 图像训练的行业领先水平全监督方法。</b><br>
			[<a href="https://ieeexplore.ieee.org/document/8859383">PDF</a>] <br>
			* 共同一作 <br>  
			</td>
		 </tr>
		 
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/video.png" class="papericon"></td>
           <td class="pub_td2">
			<u>Shizhou Dong</u>,Zhifan Gao,Sandeep Pirbhulal,Gui-Bin Bian,Heye Zhang, Wanqing Wu,Shuo Li<br>
			<b>3D convolution for video salient object detection</b><br>
			Neural Computing and Applications（IF：4.67）<br>
			<b>优点：简单有效的运动信息建模方式。</b><br>
			[<a href=“https://www.researchgate.net/profile/Shuo_Li4/publication/330142733_IoT-based_3D_convolution_for_video_salient_object_detection/links/5c2f846ea6fdccd6b590e2ef/IoT-based-3D-convolution-for-video-salient-object-detection.pdf">PDF</a>]
			</td>
		 </tr>
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/minlibmvc.png" class="papericon"></td>
           <td class="pub_td2">
			Min Li, <u>Shizhou Dong</u>, Kun Zhang, Zhifan Gao, Xi Wu, Heye Zhang, Guang Yang, Shuo Li<br>
			<b>Deep Learning intra-image and inter-images features for Co-saliency detection</b><br>
			BMVC 2018<br>
			<b>优点：通过自编码器对多张图像中相似的内容进行建模。</b><br>
			[<a href="https://www.researchgate.net/profile/Shuo_Li4/publication/327834065_Deep_Learning_intra-image_and_inter-images_features_for_Co-saliency_detection/links/5ba7eccd92851ca9ed20350e/Deep-Learning-intra-image-and-inter-images-features-for-Co-saliency-detection.pdf">PDF</a>]
			</td>
		 </tr>
		 
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/mingli.png" class="papericon"></td>
           <td class="pub_td2">
			Ming Li, <u>Shizhou Dong</u>, Zhifan Gao, Alex Pui-wai Lee, Cheng Feng, Huahua Xiong, Wei Zheng, Dhanjoo Ghista, Heye Zhang,Victor Hug C. de Albuquerque <br>
			<b>Unified model based on deep feature pyramid and deep supervision for multi-view echocardiographic sequences interpretation</b><br>
			Applied Soft Computing（SCI 一区，IF：4.87）<br>
			<b>优点：精准，鲁棒的超声心电图的自动分割。</b><br>
			</td>
		 </tr>
		 
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/network.png" class="papericon"></td>
           <td class="pub_td2">
			Zhifan Gao, Heye Zhang,<u>Shizhou Dong</u>, Shanhui Sun, Xin Wang, Guang Yang, Wanqing Wu, Shuo Li, and Victor Hugo C. de Albuquerque<br>
			<b>Salient Object Detection in the Distributed Cloud-Edge Intelligent Network</b><br>
			IEEE Network（SCI一区，IF：7.50）<br>
			<b>优点：不同语义层级的分布式显著性检测框架。</b><br>
			</td>
		 </tr>
	</tbody></table>
	
	
	<h2>个人竞赛</h2>
	<table class="pub_table">
	<tbody>
        <tr>
           <td class="pub_td1"><img src="./imgs/splogo.jpg" class="papericon"></td>
           <td class="pub_td2">
		   <b>SALICON Saliency Prediction Challenge (LSUN 2017)</b><br>
			个人竞赛<br>
			->https://competitions.codalab.org/competitions/17136##results<br>
			<b>优点 <li> Leaderboard 最高排名:第二(用户名：Jack0521)</li>
					<li> 基于图像梯度约束 Saliency Probability Map 空间平滑，性能提高 3%。</li>
			</b>
			<a href="./spresults.pdf">当前的结果</a>
			</td>
		 </tr>
    </tbody></table>
	
	<h2> 学习项目</h2>
	<table class="pub_table">
	<tbody>
        <tr>
           <td class="pub_td1"><img src="./imgs/abnomal.png" class="papericon"></td>
           <td class="pub_td2">
		   <b>城市排水管道视频异常检测</b><br>
			公司合作项目<br>
			合作公司：博铭维<br>
			指导老师：乔宇，王亚立<br>
			<b>优点 <li>自动区分视频中的井内井外时间段，自动找到异常区间。</li>
					<li>自动预测异常区间的异常位置（box），类别和等级。</li>
					<li> 设计了一套图像分类和实例分割两个任务之间相互协同学习的框架。</li>
					<li> 设计了一个新的目标函数：Large Margin  Focal Loss 解决多标签数据不平衡的问题。</li>
			</b><br>
			</td>
		 </tr>
		 
		 <tr>
           <td class="pub_td1"><img src="./imgs/license_plate.png" class="papericon"></td>
           <td class="pub_td2">
		   <b>复杂环境下的车牌定位</b><br>
			重庆绿色智能研究院实习项目<br>
			指导老师：覃勋辉<br>
			<b>优点：对图像划分亮暗区域，解决逆光情况下车牌难定位的问题。</b><br>
			<a href="./license_plate.pdf">算法详述<br>
			</a>  <a href="https://github.com/jack-Dong/muti_thread_plat_locate">Code</a>  
			</td>
		 </tr>
		 
	</tbody></table>
	
	
    <h2>Others</h2>
        <ul>
            <li>编程: Pytorch,Python, C， C++， SQL， MATLAB</li>
            <li>获奖：中国科学院大学：三好学生，所长奖学金。重庆邮电大学：优秀学生奖学金，优秀班干部，操作系统单科第一名。</li>
            <li>英语：英语六级。</li>
        </ul>    

</div>
</div>

<div id="haloword-lookup" class="ui-widget-content ui-draggable"><div id="haloword-title"><span id="haloword-word"></span><a herf="#" id="haloword-pron" class="haloword-button" title="&#21457;&#38899;"></a><audio id="haloword-audio"></audio><div id="haloword-control-container"><a herf="#" id="haloword-add" class="haloword-button" title="&#21152;&#20837;&#21333;&#35789;&#34920;"></a><a herf="#" id="haloword-remove" class="haloword-button" title="&#31227;&#20986;&#21333;&#35789;&#34920;"></a><a href="https://people.csail.mit.edu/bzhou/#" id="haloword-open" class="haloword-button" title="&#26597;&#30475;&#21333;&#35789;&#35814;&#32454;&#37322;&#20041;" target="_blank"></a><a herf="#" id="haloword-close" class="haloword-button" title="&#20851;&#38381;&#26597;&#35810;&#31383;"></a></div><br style="clear: both;"></div><div id="haloword-content"></div></div></body></html>
